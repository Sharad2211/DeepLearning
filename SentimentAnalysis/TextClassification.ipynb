import tensorflow as tf
import numpy as np
from tensorflow import keras
imdbDB = keras.datasets.imdb
(train_data,train_labels),(test_data,test_labels)=imdbDB.load_data(num_words=10000)
print (f"Training entries {len(train_data)}. Labels: {train_labels}")
print(train_data[0])
print(test_data[0])
word_index = imdbDB.get_word_index()

#add more words to the index
word_index = {k:(v+3) for k, v in word_index.items()}

word_index["<PAD>"]=0
word_index["<START>"]=1
word_index["<UNK>"]=2
word_index["<UNUSED>"]=3

#creating a value to key dictionary - reverse of the word index
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])



def decode_review (text):
  return ' '.join([reverse_word_index.get(i,"?") for i in text])

print(decode_review(train_data[0]))

train_data = keras.preprocessing.sequence.pad_sequences(train_data, 
                                                        value = word_index["<PAD>"],
                                                        padding="post",
                                                        maxlen=256)
test_data = keras.preprocessing.sequence.pad_sequences(test_data, 
                                                       value = word_index["<PAD>"],
                                                       padding="post",
                                                       maxlen=256)

vocab_size = 10000
model = keras.Sequential()
model.add(keras.layers.Embedding(vocab_size,16)) # input layer
model.add(keras.layers.GlobalAveragePooling1D()) #hidden layer
model.add(keras.layers.Dense(16,
                             activation=tf.nn.relu))  #hidden layer
model.add(keras.layers.Dense(1, activation=
                             tf.nn.sigmoid)) #output layer


model.summary()

model.compile(optimizer ="adam", loss="binary_crossentropy", metrics=["acc"])

#checking the accuracy of the model using the 10000 train data - validation sets
x_val=train_data [:10000]
partial_x_train = train_data[1000:]

y_val=train_labels [:10000]
partial_y_train = train_labels[1000:]

history= model.fit(partial_x_train,partial_y_train,epochs=40,batch_size=512,validation_data=(x_val,y_val),verbose=1)

results = model.evaluate(test_data,test_labels)

print(results)
